{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"any-llm","text":"<p><code>any-llm</code> is a Python library providing a single interface to different llm providers.</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or newer</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Install <code>any-llm</code> with the name of the provider that you plan to use</p> <pre><code>pip install any-llm-sdk[mistral,ollama]\n</code></pre> <p>Refer to pyproject.toml for a list of the options available.</p>"},{"location":"#for-ai-systems","title":"For AI Systems","text":"<p>This documentation is available in two AI-friendly formats:</p> <ul> <li>llms.txt - A structured overview with curated links to key documentation sections</li> <li>llms-full.txt - Complete documentation content concatenated into a single file</li> </ul>"},{"location":"providers/","title":"Supported Providers","text":"<p><code>any-llm</code> supports the following providers:</p> <ul> <li>OpenAI</li> <li>Anthropic</li> <li>Google</li> <li>Mistral</li> <li>Ollama</li> <li>DeepSeek</li> <li>HuggingFace</li> <li>Inception Labs</li> <li>Moonshot AI</li> <li>Nebius AI Studio</li> <li>SambaNova</li> <li>Together AI</li> <li>xAI</li> </ul> <p>You can browse the implementations via the providers folder:</p> <p>https://github.com/mozilla-ai/any-llm/tree/main/src/any_llm/providers</p>"},{"location":"api/completion/","title":"Completion","text":""},{"location":"api/completion/#completion","title":"Completion","text":""},{"location":"api/completion/#any_llm.completion","title":"<code>any_llm.completion(model, messages, **kwargs)</code>","text":"<p>Create a chat completion.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Model identifier in format 'provider/model' (e.g., 'mistral/mistral-small')</p> required <code>messages</code> <code>list[dict[str, Any]]</code> <p>List of messages for the conversation</p> required <code>**kwargs</code> <code>Any</code> <p>Additional parameters including: - tools: List of tools or Tools instance - max_turns: Maximum number of tool execution turns - api_key, api_base, etc. - Other provider-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>ChatCompletion</code> <p>The completion response from the provider</p> Source code in <code>src/any_llm/main.py</code> <pre><code>def completion(model: str, messages: list[dict[str, Any]], **kwargs: Any) -&gt; ChatCompletion:\n    \"\"\"Create a chat completion.\n\n    Args:\n        model: Model identifier in format 'provider/model' (e.g., 'mistral/mistral-small')\n        messages: List of messages for the conversation\n        **kwargs: Additional parameters including:\n            - tools: List of tools or Tools instance\n            - max_turns: Maximum number of tool execution turns\n            - api_key, api_base, etc.\n            - Other provider-specific parameters\n\n    Returns:\n        The completion response from the provider\n\n    \"\"\"\n    # Check that correct format is used\n    if \"/\" not in model:\n        msg = f\"Invalid model format. Expected 'provider/model', got '{model}'\"\n        raise ValueError(msg)\n\n    # Extract the provider key from the model identifier, e.g., \"mistral/mistral-small\"\n    provider_key, model_name = model.split(\"/\", 1)\n\n    # Validate that neither provider nor model name is empty\n    if not provider_key or not model_name:\n        msg = f\"Invalid model format. Expected 'provider/model', got '{model}'\"\n        raise ValueError(msg)\n\n    # Validate if the provider is supported\n    supported_providers = ProviderFactory.get_supported_providers()\n    if provider_key not in supported_providers:\n        msg = f\"{provider_key} is not a supported provider. Supported providers: {supported_providers}. Make sure the model string is formatted correctly as 'provider/model'.\"\n        raise ValueError(msg)\n\n    # Create provider instance\n    config: dict[str, str] = {}\n    if \"api_key\" in kwargs:\n        config[\"api_key\"] = str(kwargs.pop(\"api_key\"))\n    if \"api_base\" in kwargs:\n        config[\"api_base\"] = str(kwargs.pop(\"api_base\"))\n    api_config = ApiConfig(**config)\n\n    provider = ProviderFactory.create_provider(provider_key, api_config)\n\n    return provider.completion(model_name, messages, **kwargs)\n</code></pre>"}]}