from typing import Literal

from pydantic import BaseModel


class Choice:
    """Choice in a chat completion."""

    def __init__(self) -> None:
        """Initialize the Choice."""
        self.finish_reason: Literal["stop", "tool_calls"] | None = None
        self.message = Message(
            content=None,
            tool_calls=None,
            role="assistant",
            refusal=None,
            reasoning_content=None,
        )
        self.intermediate_messages: list[Message] = []


class ChatCompletionResponse:
    """Conform to the response model of OpenAI."""

    def __init__(self) -> None:
        """Initialize the ChatCompletionResponse."""
        self.choices = [Choice()]
        self.usage: CompletionUsage | None = None


class Function(BaseModel):
    """Function in a chat completion."""

    arguments: str
    name: str


class ChatCompletionMessageToolCall(BaseModel):
    """Chat completion message tool call."""

    id: str
    function: Function
    type: Literal["function"]


class Message(BaseModel):
    """Message in a chat completion."""

    content: str | None = None
    reasoning_content: str | None = None
    tool_calls: list[ChatCompletionMessageToolCall] | None = None
    role: Literal["user", "assistant", "system", "tool"] | None = None
    refusal: str | None = None


class CompletionTokensDetails(BaseModel):
    """Completion tokens details."""

    accepted_prediction_tokens: int | None = None
    """
    When using Predicted Outputs, the number of tokens in the prediction that
    appeared in the completion.
    """

    audio_tokens: int | None = None
    """Audio input tokens generated by the model."""

    reasoning_tokens: int | None = None
    """Tokens generated by the model for reasoning."""

    rejected_prediction_tokens: int | None = None
    """
    When using Predicted Outputs, the number of tokens in the prediction that did
    not appear in the completion. However, like reasoning tokens, these tokens are
    still counted in the total completion tokens for purposes of billing, output,
    and context window limits.
    """


class PromptTokensDetails(BaseModel):
    """Prompt tokens details."""

    text_tokens: int | None = None
    """Tokens generated by the model for text."""

    audio_tokens: int | None = None
    """Audio input tokens present in the prompt."""

    cached_tokens: int | None = None
    """Cached tokens present in the prompt."""


class CompletionUsage(BaseModel):
    """Completion usage."""

    completion_tokens: int | None = None
    """Number of tokens in the generated completion."""

    prompt_tokens: int | None = None
    """Number of tokens in the prompt."""

    total_tokens: int | None = None
    """Total number of tokens used in the request (prompt + completion)."""

    completion_tokens_details: CompletionTokensDetails | None = None
    """Breakdown of tokens used in a completion."""

    prompt_tokens_details: PromptTokensDetails | None = None
    """Breakdown of tokens used in the prompt."""
